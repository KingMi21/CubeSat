{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665c2f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import shutil\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a381bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset_path, output_dir=\"cubesat_dataset\", train_count=200, val_count=50):\n",
    "    \"\"\"Создаем датасет для обучения\"\"\"\n",
    "    data_path = Path(dataset_path)\n",
    "    dataset_dir = Path(output_dir)\n",
    "\n",
    "    # Создание структуры директорий\n",
    "    for folder in [\"images/train\", \"images/val\", \"labels/train\", \"labels/val\"]:\n",
    "        (dataset_dir / folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Загрузка предобученной модели для авторазметки\n",
    "    model = YOLO('yolov8n.pt')\n",
    "\n",
    "    # Получение тренировочных изображений (первые train_count)\n",
    "    train_images = list((data_path / \"train\" / \"images\").glob(\"*.jpg\"))[:train_count]\n",
    "    print(f\"Обрабатываем {len(train_images)} тренировочных изображений...\")\n",
    "\n",
    "    for img_path in train_images:\n",
    "        # Копирование изображения\n",
    "        dst = dataset_dir / \"images\" / \"train\" / img_path.name\n",
    "        shutil.copy(img_path, dst)\n",
    "\n",
    "        # Детекция кубсатов с низким порогом уверенности (0.1)\n",
    "        results = model(img_path, conf=0.1, verbose=False)\n",
    "\n",
    "        with open(dataset_dir / \"labels\" / \"train\" / f\"{img_path.stem}.txt\", 'w') as f:\n",
    "            if results[0].boxes is not None:\n",
    "                img = cv2.imread(str(img_path))\n",
    "                h, w = img.shape[:2]\n",
    "\n",
    "                for box in results[0].boxes:\n",
    "                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                    # Конвертация координат в YOLO-формат (нормализованные центры)\n",
    "                    x_center = ((x1 + x2) / 2) / w\n",
    "                    y_center = ((y1 + y2) / 2) / h\n",
    "                    width = (x2 - x1) / w\n",
    "                    height = (y2 - y1) / h\n",
    "\n",
    "                    # Фильтрация слишком маленьких объектов\n",
    "                    if width > 0.01 and height > 0.01:\n",
    "                        f.write(f\"0 {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
    "\n",
    "    # Аналогичная обработка валидационных изображений\n",
    "    val_images = list((data_path / \"val\" / \"images\").glob(\"*.jpg\"))[:val_count]\n",
    "    print(f\"Обрабатываем {len(val_images)} валидационных изображений...\")\n",
    "\n",
    "    for img_path in val_images:\n",
    "        dst = dataset_dir / \"images\" / \"val\" / img_path.name\n",
    "        shutil.copy(img_path, dst)\n",
    "\n",
    "        results = model(img_path, conf=0.1, verbose=False)\n",
    "\n",
    "        with open(dataset_dir / \"labels\" / \"val\" / f\"{img_path.stem}.txt\", 'w') as f:\n",
    "            if results[0].boxes is not None:\n",
    "                img = cv2.imread(str(img_path))\n",
    "                h, w = img.shape[:2]\n",
    "\n",
    "                for box in results[0].boxes:\n",
    "                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "                    x_center = ((x1 + x2) / 2) / w\n",
    "                    y_center = ((y1 + y2) / 2) / h\n",
    "                    width = (x2 - x1) / w\n",
    "                    height = (y2 - y1) / h\n",
    "\n",
    "                    if width > 0.01 and height > 0.01:\n",
    "                        f.write(f\"0 {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
    "\n",
    "    # Создание YAML-конфигурации датасета\n",
    "    config = {\n",
    "        'path': str(dataset_dir.absolute()),  # Абсолютный путь к датасету\n",
    "        'train': 'images/train',              # Путь к тренировочным изображениям\n",
    "        'val': 'images/val',                  # Путь к валидационным изображениям\n",
    "        'nc': 1,                              # Количество классов\n",
    "        'names': ['cubesat']                  # Имена классов\n",
    "    }\n",
    "\n",
    "    yaml_path = dataset_dir / \"dataset.yaml\"\n",
    "    with open(yaml_path, 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "\n",
    "    return yaml_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05adaca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data_yaml):\n",
    "    \"\"\"Обучаем модель\"\"\"\n",
    "    model = YOLO('yolov8n.pt')\n",
    "\n",
    "    results = model.train(\n",
    "        data=str(data_yaml),  # Путь к конфигурации датасета\n",
    "        epochs=50,            # Количество эпох обучения\n",
    "        imgsz=640,            # Размер входного изображения\n",
    "        batch=16,             # Размер батча (оптимально для 8GB VRAM)\n",
    "        device='cuda',        # Использование GPU\n",
    "        workers=4,            # Количество процессов загрузки данных\n",
    "        amp=True,             # Mixed precision training для экономии памяти\n",
    "        lr0=0.01,             # Начальная скорость обучения\n",
    "        augment=True,         # Аугментация данных\n",
    "        save=True,            # Сохранение чекпоинтов\n",
    "        plots=True,           # Генерация графиков обучения\n",
    "        val=True,             # Валидация после каждой эпохи\n",
    "        exist_ok=True,        # Перезапись существующих runs\n",
    "        pretrained=True,      # Использование предобученных весов\n",
    "        verbose=True,         # Подробный вывод процесса\n",
    "    )\n",
    "\n",
    "    # Сохранение лучшей модели в корень проекта\n",
    "    if Path('runs/detect/train/weights/best.pt').exists():\n",
    "        shutil.copy('runs/detect/train/weights/best.pt', 'best.pt')\n",
    "        print(\"\\nМодель сохранена как 'best.pt'\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b458ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Путь к исходному датасету\n",
    "    dataset_path = r\"C:\\\\Users\\\\ASUS\\\\.cache\\\\kagglehub\\\\datasets\\\\eberhardtkorf\\\\synthetic-cubesat\\\\versions\\\\1\\\\synthetic_cubesat\\\\dataset\"\n",
    "\n",
    "    print(\"Создание датасета...\")\n",
    "    data_yaml = create_dataset(dataset_path)\n",
    "\n",
    "    print(\"\\nОбучение модели...\")\n",
    "    train_model(data_yaml)\n",
    "\n",
    "    print(\"\\nОбучение завершено\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da30bb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
